{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP7OFYHonbAMrGaVifrM5HV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rosafilgueira/Workflows_Seminar/blob/main/Intro_Tutorial_dispel4py_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dispel4py Tutorial\n",
        "\n",
        "In this notebook, we embark on an exploratory journey into the world of [dispel4py](https://github.com/StreamingFlow/d4py), a Python library designed to craft and execute complex data-intensive workflows. Aimed at both novices and seasoned developers, this guide offers a comprehensive introduction to setting up, writing, and running dispel4py workflows with a focus on its versatile capabilities to handle a myriad of computational tasks efficiently."
      ],
      "metadata": {
        "id": "gRyT_WdWI4LL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Started with dispel4py\n",
        "\n",
        "Our journey begins with the installation of dispel4py, ensuring you have the necessary tools to dive into data processing. We present two distinct approaches to install dispel4py:\n",
        "\n",
        "* Version 1: Direct installation using pip, suitable for quickly adding dispel4py and its stream-d4py companion to your Python environment.\n",
        "\n",
        "\n",
        "* Version 2: For those preferring the latest versions or contributing to development, cloning from the GitHub repository and manual installation offers the cutting edge of dispel4py functionalities."
      ],
      "metadata": {
        "id": "uZ_1ANt1_dxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Version 1:\n",
        "#!pip install mpi4py\n",
        "!pip install stream-d4py\n",
        "\n",
        "# Version 2:\n",
        "#!git clone https://github.com/StreamingFlow/d4py.git\n",
        "#%cd d4py\n",
        "#!pip install mpi4py\n",
        "#!python setup.py install"
      ],
      "metadata": {
        "id": "9qUHZKAJ9L-z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f47ef9c4-72e6-4599-c344-039df8023d64"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stream-d4py in /usr/local/lib/python3.10/dist-packages (2.9.1)\n",
            "Requirement already satisfied: flake8 in /usr/local/lib/python3.10/dist-packages (from stream-d4py) (7.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from stream-d4py) (3.2.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from stream-d4py) (23.2.1)\n",
            "Requirement already satisfied: redis in /usr/local/lib/python3.10/dist-packages (from stream-d4py) (5.0.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from stream-d4py) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stream-d4py) (4.66.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from stream-d4py) (2.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from stream-d4py) (67.7.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from stream-d4py) (15.0.1)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.10/dist-packages (from stream-d4py) (5.9.0)\n",
            "Requirement already satisfied: jwt in /usr/local/lib/python3.10/dist-packages (from stream-d4py) (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stream-d4py) (1.25.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->stream-d4py) (10.0)\n",
            "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from flake8->stream-d4py) (0.7.0)\n",
            "Requirement already satisfied: pycodestyle<2.12.0,>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from flake8->stream-d4py) (2.11.1)\n",
            "Requirement already satisfied: pyflakes<3.3.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from flake8->stream-d4py) (3.2.0)\n",
            "Requirement already satisfied: cryptography!=3.4.0,>=3.1 in /usr/local/lib/python3.10/dist-packages (from jwt->stream-d4py) (42.0.5)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis->stream-d4py) (4.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography!=3.4.0,>=3.1->jwt->stream-d4py) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography!=3.4.0,>=3.1->jwt->stream-d4py) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functons to copy cells into files\n",
        "\n",
        "We are going to use the functions bellow to copy the code that we have in cell text into files, so later we can run dispel4py using the command line and given it dispel4py workflows stored as files."
      ],
      "metadata": {
        "id": "s6jrWPmuMPi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# some magic so we can copy \"text cells\" into file\n",
        "from google.colab import _message\n",
        "\n",
        "def write_cell_above_to_file(search_term, filename):\n",
        "  cell = get_cell_above(search_term)\n",
        "  code_block = get_cell_code_block(cell)\n",
        "  with open(filename, 'w') as fp:\n",
        "    fp.writelines(code_block)\n",
        "\n",
        "def get_cell_above(search_term):\n",
        "  # Load the notebook JSON.\n",
        "  nb = _message.blocking_request('get_ipynb')\n",
        "\n",
        "  # Search for current markdown cell (using search term)\n",
        "  for i, cell in enumerate(nb['ipynb']['cells']):\n",
        "    if search_term in ''.join(cell['source']):\n",
        "      return nb['ipynb']['cells'][i - 1]\n",
        "\n",
        "def get_cell_code_block(cell):\n",
        "  # Get the code block in previous cell\n",
        "  cell_lines = cell['source']\n",
        "  code_block = []\n",
        "  in_block = False\n",
        "  for ln in cell_lines:\n",
        "    if '```' in ln:\n",
        "      in_block = not in_block  # boolean switch\n",
        "    else:\n",
        "      if in_block:\n",
        "        code_block.append(ln)\n",
        "  return code_block\n"
      ],
      "metadata": {
        "id": "7jC_9egfEaAr"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing dispel4py\n",
        "\n",
        "As we delve deeper, we transition from installation to execution, showcasing how dispel4py simplifies the process of defining and running data-driven workflows.\n",
        "\n",
        "\n",
        "Our exploration covers various \"mappings\" - execution strategies that dispel4py employs to adapt workflows for different computing environments, ranging from sequential processing on a single core to distributed computing across multiple nodes, demonstrating dispel4py's flexibility and scalability. Here we are going to test two mappings:\n",
        "  * simple: sequential execution\n",
        "  * multi: parallel (shared memory) execution"
      ],
      "metadata": {
        "id": "o5YMR3-N_jRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Simple mapping\n",
        "!dispel4py simple dispel4py.examples.graph_testing.word_count -i 10"
      ],
      "metadata": {
        "id": "uT3SQpxb_nVq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cc64fca-f634-47c6-bdbb-e70ebd1dbf38"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 10 iterations.\n",
            "RUN ARGS: \n",
            "Namespace(target='simple', module='dispel4py.examples.graph_testing.word_count', attr=None, file=None, data=None, iter=10, provenance=None)\n",
            "==========\n",
            "Inputs: {'RandomWordProducer0': 10}\n",
            "SimplePE: Processed 1 iteration.\n",
            "Outputs: {'WordCounter1': {'output': [['Computing', 1], ['Modelling', 1], ['Modelling', 2], ['Modelling', 3], ['Analysis', 1], ['Seismology', 1], ['Earthquake', 1], ['Infrastructure', 1], ['Seismology', 2], ['Modelling', 4]]}}\n",
            "ELAPSED TIME: 0.0008900165557861328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Multi mapping\n",
        "!dispel4py multi dispel4py.examples.graph_testing.word_count -i 10 -n 4"
      ],
      "metadata": {
        "id": "9MKCGez9_1fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b4389b4-36ca-41fe-cdf3-a8d7f355bb11"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 10 iterations.\n",
            "RUN ARGS: \n",
            "Namespace(target='multi', module='dispel4py.examples.graph_testing.word_count', attr=None, file=None, data=None, iter=10, provenance=None, simple=False, num=4)\n",
            "==========\n",
            "Processes: {'RandomWordProducer0': range(0, 1), 'WordCounter1': range(1, 4)}\n",
            "RandomWordProducer0 (rank 0): Processed 10 iterations.\n",
            "WordCounter1 (rank 1): Processed 6 iterations.\n",
            "WordCounter1 (rank 2): Processed 3 iterations.\n",
            "WordCounter1 (rank 3): Processed 1 iteration.\n",
            "ELAPSED TIME: 0.03533649444580078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to create my first dispel4py workflow\n",
        "\n",
        "This tutorial is an introduction to dispel4py. We will see how to write dispel4py PEs, how to connect them together to form a workflow and how this workflow is executed in different environments.\n",
        "How to write a PE\n",
        "\n",
        "In this section we are going to implement our first PE.\n",
        "\n",
        "First you need to decide what kind of processing the PE will do and what the data units are that it processes. In our example we are implementing a PE that decides if a number is divisible by another number. The PE is configured with this divisor and for each input data item it tests whether the number can be divided by this divisor. It sends the input data item to its output stream if it is not divisible.\n",
        "Create a PE class\n",
        "\n",
        "To start with we create a PE that does only very few things"
      ],
      "metadata": {
        "id": "TgGwbLsB-pRD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a PE class\n",
        "\n",
        "To start with we create a PE that does only very few things:\n"
      ],
      "metadata": {
        "id": "gWP2v228_FgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dispel4py.base import IterativePE\n",
        "\n",
        "class MyFirstPE(IterativePE):\n",
        "\n",
        "    def __init__(self, divisor):\n",
        "        IterativePE.__init__(self)\n",
        "        self.divisor = divisor"
      ],
      "metadata": {
        "id": "Wy8qXC-9_H9n"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case we extend the base class `dispel4py.base.IterativePE` which defines one input and one output, which is exactly what we need. We pass the divisor as an initialisation parameter to the object which stores it."
      ],
      "metadata": {
        "id": "wftAgaoN_M37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement the processing method\n",
        "\n",
        "Now the actual work begins: We have to implement the processing method. This is done by overriding the method of the superclass:"
      ],
      "metadata": {
        "id": "BjGXF1Cw_UdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _process(self, data):\n",
        "    None"
      ],
      "metadata": {
        "id": "eih-fht4_Tuf"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We fill in the processing commands, in our case this means that we test if the input data item is divisible by our divisor, and return it if it is not divisible:"
      ],
      "metadata": {
        "id": "88H1_BqL_c9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _process(self, data):\n",
        "    if not data % self.divisor:\n",
        "        return data"
      ],
      "metadata": {
        "id": "EtNv5q54_f-1"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data returned by _process is written to the output stream of the PE.\n",
        "\n",
        "That’s it! Our first PE is complete"
      ],
      "metadata": {
        "id": "W5YAKDzA_ihm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dispel4py.base import IterativePE\n",
        "\n",
        "class MyFirstPE(IterativePE):\n",
        "\n",
        "    def __init__(self, divisor):\n",
        "        IterativePE.__init__(self)\n",
        "        self.divisor = divisor\n",
        "    def _process(self, data):\n",
        "        #print(\"divisor is %s, data is %s\" %(self.divisor, data))\n",
        "        if not data % self.divisor == 0:\n",
        "            print(\"This: %s,  is not divisible by divisor the %s\" %(data,self.divisor))\n",
        "            return data\n"
      ],
      "metadata": {
        "id": "mfhIPbsU_me-"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Summary of our first PE\n",
        "\n",
        "Here's a breakdown of what MyFirstPE does:\n",
        "\n",
        "* __init__(self, divisor): This is the initializer method that gets called when an instance of MyFirstPE is created. It initializes the parent IterativePE class and sets up a divisor attribute, which is used to determine if the incoming data should be processed or not.\n",
        "\n",
        "* _process(self, data): This method is called for each data item in the stream. The data item is passed to this method as the data argument.\n",
        "  * Inside _process, it checks if the data item is not divisible by the divisor attribute (if not data % self.divisor == 0:). If the condition is true (meaning the data item is not a multiple of the divisor), it prints the data and then returns it.\n",
        "\n",
        "The PE essentially filters and outputs data items that are not divisible by a specified number. Items that are divisible by this number are effectively ignored, and do not pass through this processing element.\n",
        "\n",
        "Note that the print statement is commented out, but if uncommented, it would print a message each time a non-divisible item is processed"
      ],
      "metadata": {
        "id": "gaBXy5aeHaeS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a simple workflow\n",
        "\n",
        "In this section we are going to create a workflow, using the PE that we implemented in the previous section. There’s a useful PE in the library of dispel4py PEs that just produces a sequence of numbers.\n",
        "\n",
        "We can connect this number producer to our PE which is initialised with the divisor 3 in this example:\n"
      ],
      "metadata": {
        "id": "uoQhH5XE_lOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dispel4py.workflow_graph import WorkflowGraph\n",
        "from dispel4py.examples.graph_testing.testing_PEs import TestProducer\n",
        "\n",
        "producer = TestProducer()\n",
        "divide = MyFirstPE(3)\n",
        "\n",
        "graph = WorkflowGraph()\n",
        "graph.connect(producer, 'output', divide, 'input')"
      ],
      "metadata": {
        "id": "ABBqOSu-_unS"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This workflow produces integers and tests whether they are divisible by 3. Any numbers that are not divisible by 3 will be written to the unconnected output stream of our first PE."
      ],
      "metadata": {
        "id": "W_Afi5Is_xtN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execute the workflow\n",
        "\n",
        "To run this workflow you can use the sequential simple processor:\n"
      ],
      "metadata": {
        "id": "-bR7GhdF_2uC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dispel4py.new.simple_process import process as simple_process\n",
        "simple_process(graph, {producer: 20})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhcCZpU7_1xH",
        "outputId": "6847422c-fb14-4b88-c902-71d1794978d4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs: {'TestProducer8': 20}\n",
            "This: 1,  is not divisible by divisor the 3\n",
            "This: 2,  is not divisible by divisor the 3\n",
            "This: 4,  is not divisible by divisor the 3\n",
            "This: 5,  is not divisible by divisor the 3\n",
            "This: 7,  is not divisible by divisor the 3\n",
            "This: 8,  is not divisible by divisor the 3\n",
            "This: 10,  is not divisible by divisor the 3\n",
            "This: 11,  is not divisible by divisor the 3\n",
            "This: 13,  is not divisible by divisor the 3\n",
            "This: 14,  is not divisible by divisor the 3\n",
            "This: 16,  is not divisible by divisor the 3\n",
            "This: 17,  is not divisible by divisor the 3\n",
            "This: 19,  is not divisible by divisor the 3\n",
            "This: 20,  is not divisible by divisor the 3\n",
            "SimplePE: Processed 1 iteration.\n",
            "Outputs: {'MyFirstPE9': {'output': [1, 2, 4, 5, 7, 8, 10, 11, 13, 14, 16, 17, 19, 20]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write a data producer PE\n",
        "\n",
        "#### Producing the input\n",
        "\n",
        "Next we will create a ProducerPE that creates the input for our first PE. The test producer that we were using above only produces one number per iteration. In our case we would like to create a PE that produces all the numbers from 2 up to a certain limit.\n",
        "\n",
        "The implementation looks like this:\n",
        "i"
      ],
      "metadata": {
        "id": "drUvFRAsAn9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dispel4py.base import ProducerPE\n",
        "\n",
        "class NumberProducer(ProducerPE):\n",
        "    def __init__(self, start, limit):\n",
        "        ProducerPE.__init__(self)\n",
        "        self.start = start\n",
        "        self.limit = limit\n",
        "    def _process(self, inputs):\n",
        "        for i in range(self.start, self.limit):\n",
        "            #print(\"I have produced the data %s\" %i)\n",
        "            self.write('output', i)\n",
        "            # OR: self.write(\"ProducerPE.OUTPUT_NAME\", i)"
      ],
      "metadata": {
        "id": "kRM7E_ARAwQV"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This introduces several new concepts. The ProducerPE is a base class which has no inputs and one output ProducerPE.OUTPUT_NAME or \"output\". We initialise an instance of the NumberProducer PE with the lower and upper bounds for the integers that we want to produce.\n",
        "\n",
        "In the implementation of the _process() method we iterate over the range of numbers from the lower bound up to (and excluding) the upper bound. Since the processing method generates more than one data item we have to write them one at a time to the output data stream using the write() method."
      ],
      "metadata": {
        "id": "W4jqSqwNA0-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using the producer in the workflow\n",
        "\n",
        "Now we hook our own producer into the workflow, replacing the TestProducer from the dispel4py library:"
      ],
      "metadata": {
        "id": "7WE0zokUA7kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dispel4py.workflow_graph import WorkflowGraph\n",
        "\n",
        "producer = NumberProducer(2, 100)\n",
        "divide = MyFirstPE(3)\n",
        "graph = WorkflowGraph()\n",
        "graph.connect(producer, 'output', divide, 'input')"
      ],
      "metadata": {
        "id": "sd9VIbXrAz4W"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Everything else stays the same. We create an instance of the NumberProducer that outputs the range of numbers from 2 to 99 (excluding the upper bound of 100).\n",
        "\n",
        "Now execute the new workflow using the simple mapping:\n"
      ],
      "metadata": {
        "id": "4VfHurwABDmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_process(graph, {producer: 1})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPMYVKcpBCdK",
        "outputId": "1ca56b29-0907-4b32-cc93-ca717e27d6e7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs: {'NumberProducer10': 1}\n",
            "This: 2,  is not divisible by divisor the 3\n",
            "This: 4,  is not divisible by divisor the 3\n",
            "This: 5,  is not divisible by divisor the 3\n",
            "This: 7,  is not divisible by divisor the 3\n",
            "This: 8,  is not divisible by divisor the 3\n",
            "This: 10,  is not divisible by divisor the 3\n",
            "This: 11,  is not divisible by divisor the 3\n",
            "This: 13,  is not divisible by divisor the 3\n",
            "This: 14,  is not divisible by divisor the 3\n",
            "This: 16,  is not divisible by divisor the 3\n",
            "This: 17,  is not divisible by divisor the 3\n",
            "This: 19,  is not divisible by divisor the 3\n",
            "This: 20,  is not divisible by divisor the 3\n",
            "This: 22,  is not divisible by divisor the 3\n",
            "This: 23,  is not divisible by divisor the 3\n",
            "This: 25,  is not divisible by divisor the 3\n",
            "This: 26,  is not divisible by divisor the 3\n",
            "This: 28,  is not divisible by divisor the 3\n",
            "This: 29,  is not divisible by divisor the 3\n",
            "This: 31,  is not divisible by divisor the 3\n",
            "This: 32,  is not divisible by divisor the 3\n",
            "This: 34,  is not divisible by divisor the 3\n",
            "This: 35,  is not divisible by divisor the 3\n",
            "This: 37,  is not divisible by divisor the 3\n",
            "This: 38,  is not divisible by divisor the 3\n",
            "This: 40,  is not divisible by divisor the 3\n",
            "This: 41,  is not divisible by divisor the 3\n",
            "This: 43,  is not divisible by divisor the 3\n",
            "This: 44,  is not divisible by divisor the 3\n",
            "This: 46,  is not divisible by divisor the 3\n",
            "This: 47,  is not divisible by divisor the 3\n",
            "This: 49,  is not divisible by divisor the 3\n",
            "This: 50,  is not divisible by divisor the 3\n",
            "This: 52,  is not divisible by divisor the 3\n",
            "This: 53,  is not divisible by divisor the 3\n",
            "This: 55,  is not divisible by divisor the 3\n",
            "This: 56,  is not divisible by divisor the 3\n",
            "This: 58,  is not divisible by divisor the 3\n",
            "This: 59,  is not divisible by divisor the 3\n",
            "This: 61,  is not divisible by divisor the 3\n",
            "This: 62,  is not divisible by divisor the 3\n",
            "This: 64,  is not divisible by divisor the 3\n",
            "This: 65,  is not divisible by divisor the 3\n",
            "This: 67,  is not divisible by divisor the 3\n",
            "This: 68,  is not divisible by divisor the 3\n",
            "This: 70,  is not divisible by divisor the 3\n",
            "This: 71,  is not divisible by divisor the 3\n",
            "This: 73,  is not divisible by divisor the 3\n",
            "This: 74,  is not divisible by divisor the 3\n",
            "This: 76,  is not divisible by divisor the 3\n",
            "This: 77,  is not divisible by divisor the 3\n",
            "This: 79,  is not divisible by divisor the 3\n",
            "This: 80,  is not divisible by divisor the 3\n",
            "This: 82,  is not divisible by divisor the 3\n",
            "This: 83,  is not divisible by divisor the 3\n",
            "This: 85,  is not divisible by divisor the 3\n",
            "This: 86,  is not divisible by divisor the 3\n",
            "This: 88,  is not divisible by divisor the 3\n",
            "This: 89,  is not divisible by divisor the 3\n",
            "This: 91,  is not divisible by divisor the 3\n",
            "This: 92,  is not divisible by divisor the 3\n",
            "This: 94,  is not divisible by divisor the 3\n",
            "This: 95,  is not divisible by divisor the 3\n",
            "This: 97,  is not divisible by divisor the 3\n",
            "This: 98,  is not divisible by divisor the 3\n",
            "SimplePE: Processed 1 iteration.\n",
            "Outputs: {'MyFirstPE11': {'output': [2, 4, 5, 7, 8, 10, 11, 13, 14, 16, 17, 19, 20, 22, 23, 25, 26, 28, 29, 31, 32, 34, 35, 37, 38, 40, 41, 43, 44, 46, 47, 49, 50, 52, 53, 55, 56, 58, 59, 61, 62, 64, 65, 67, 68, 70, 71, 73, 74, 76, 77, 79, 80, 82, 83, 85, 86, 88, 89, 91, 92, 94, 95, 97, 98]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using the comand line\n",
        "\n",
        "You should save the PEs (NumberProducer, MyFristPE) and the graph as myfirstgraph.py file. Once saved, you could run it using the sequential simple processor.\n",
        "\n",
        "For this we are going to use the `write_cell_above_to file` function.\n",
        "\n",
        "Remember, that each time we use this function is going to copy the cell above into the desired file (e.g. `myfirstgraph.py`), and it needs a unique identifier each time (e.g. `id:example1a`).\n",
        "\n",
        "**Note**: You can also upload the `myfirstgraph.py` workflow, downloading first to your local machine from [here](https://github.com/rosafilgueira/Workflows_Seminar/blob/main/d4py_tutorial_workflows/myfirstgraph.py) and upload it to this Notebook later.\n"
      ],
      "metadata": {
        "id": "kkRgvIneDTs8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "from dispel4py.base import ProducerPE\n",
        "from dispel4py.base import IterativePE\n",
        "from dispel4py.workflow_graph import WorkflowGraph\n",
        "\n",
        "\n",
        "class NumberProducer(ProducerPE):\n",
        "    def __init__(self, start, limit):\n",
        "        ProducerPE.__init__(self)\n",
        "        self.start = start\n",
        "        self.limit = limit\n",
        "    def _process(self, inputs):\n",
        "        for i in range(self.start, self.limit):\n",
        "            self.write('output', i)\n",
        "\n",
        "class MyFirstPE(IterativePE):\n",
        "\n",
        "    def __init__(self, divisor):\n",
        "        IterativePE.__init__(self)\n",
        "        self.divisor = divisor\n",
        "\n",
        "    def _process(self, data):\n",
        "        if not data % self.divisor == 0:\n",
        "            return data\n",
        "\n",
        "producer = NumberProducer(2, 100)\n",
        "divide = MyFirstPE(3)\n",
        "graph = WorkflowGraph()\n",
        "graph.connect(producer, 'output', divide, 'input')\n",
        "```"
      ],
      "metadata": {
        "id": "atRpV6HAEpwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <font size='4'>Run the cell above</font>\n",
        "search_term = 'id:example1a'\n",
        "write_cell_above_to_file(search_term, 'myfirstgraph.py')"
      ],
      "metadata": {
        "id": "TMqiVrljFNJi"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!dispel4py simple myfirstgraph.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZa-D8FwFZBt",
        "outputId": "38b3cf1a-e857-43fb-d590-e0abaa7e68e4"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 1 iteration.\n",
            "RUN ARGS: \n",
            "Namespace(target='simple', module='myfirstgraph.py', attr=None, file=None, data=None, iter=1, provenance=None)\n",
            "==========\n",
            "Inputs: {'NumberProducer0': 1}\n",
            "SimplePE: Processed 1 iteration.\n",
            "Outputs: {'MyFirstPE1': {'output': [2, 4, 5, 7, 8, 10, 11, 13, 14, 16, 17, 19, 20, 22, 23, 25, 26, 28, 29, 31, 32, 34, 35, 37, 38, 40, 41, 43, 44, 46, 47, 49, 50, 52, 53, 55, 56, 58, 59, 61, 62, 64, 65, 67, 68, 70, 71, 73, 74, 76, 77, 79, 80, 82, 83, 85, 86, 88, 89, 91, 92, 94, 95, 97, 98]}}\n",
            "ELAPSED TIME: 0.0011785030364990234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parallel processing\n",
        "\n",
        "For this very simple case we can easily parallelise the execution of the workflow. To do this we use the dispel4py multi mapping that executes a workflow in multiple processes using the Python multiprocessing [1](https://docs.python.org/2/library/multiprocessing.html) library. Lets run it with 4 processes"
      ],
      "metadata": {
        "id": "WeYEkonhJEXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!dispel4py multi myfirstgraph.py -n 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZ1OkrpOFmNL",
        "outputId": "d56df761-74e4-4871-9a7d-212043faff6d"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 1 iteration.\n",
            "RUN ARGS: \n",
            "Namespace(target='multi', module='myfirstgraph.py', attr=None, file=None, data=None, iter=1, provenance=None, simple=False, num=4)\n",
            "==========\n",
            "Processes: {'NumberProducer0': range(0, 1), 'MyFirstPE1': range(1, 4)}\n",
            "NumberProducer0 (rank 0): Processed 1 iteration.\n",
            "MyFirstPE1 (rank 2): Processed 33 iterations.\n",
            "MyFirstPE1 (rank 3): Processed 32 iterations.\n",
            "MyFirstPE1 (rank 1): Processed 33 iterations.\n",
            "ELAPSED TIME: 0.02984619140625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, MyFirstPE is assigned to processes 1, 2 and 3, so there three parallel instances. These instances each process about a third of the data, as you can see from the output of the instances when processing is complete:\n",
        "\n",
        "```\n",
        "MyFirstPE3 (rank 1): Processed 33 iterations.\n",
        "MyFirstPE3 (rank 2): Processed 33 iterations.\n",
        "MyFirstPE3 (rank 3): Processed 32 iterations.\n",
        "````\n",
        "\n",
        "Note that when executing in a parallel environment the output from each PE is not collected as in the simple mapping. You are responsible for collecting this output and printing or storing it."
      ],
      "metadata": {
        "id": "Wj73WJ5GJidX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Even humans are odd!\n",
        "\n",
        "In this exercise we are going to create a dispel4py workflow that produces random numbers and it pairs them by (\"one odd\",\"one even\") pattern. As we introduced before, we have different types of PEs: Generic, Iterative, Producer, Consumerk, SimpleFunction, ... In this exercise we are going to get familiar with the following ones: GenericPE, IterativePE and ProducerPE.\n",
        "\n",
        "The first step is to create a PE class that produces a random integer number at the time in a range 1 to 1000, as we did in the \"prime\" workflow.\n",
        "\n",
        "Because this PE is our first one in this workflow and it has not any input streams, the most sensible choice is to use a ProducerPE type. However, we could also use a GenericPE type as well. Feel free to modify this ipython notebook to change it as you like.\n",
        "\n",
        "One quick comment about how to write data to the output streams. There are two options:\n",
        "\n",
        "* return: it only provides one value. Then the process method is finished.\n",
        "* self.write: it can produce one or more value(s) during processing. Then it can continue to process (e.g. providing one/several value(s) in a loop).\n",
        "\n",
        "For this PE we could use both formats, as you can see in the following code. You could comment the one that you like less.\n"
      ],
      "metadata": {
        "id": "EOO-A2D_Jwtk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dispel4py.base import ProducerPE\n",
        "import random\n",
        "\n",
        "class NumberProducer(ProducerPE):\n",
        "    def __init__(self):\n",
        "        ProducerPE.__init__(self)\n",
        "\n",
        "    def _process(self , inputs):\n",
        "        result= random.randint(1, 1000)\n",
        "        return result\n",
        "        #OR: self.write('output', result)"
      ],
      "metadata": {
        "id": "9icDAvjKJt7d"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After building the \"NumberProducer\" PE class, its output stream will be sent to another PE class (Divideby2) to determine if the number that has just been produced is even or odd. One way to perform this task is by dividing the the number by 2 and checking the reminder. If the reminder is equal 0, the number is even. Otherwise the number is odd. We are going to use a parameter (called \"compare\") for comparing the reminder with 0 and 1, and therefore reuse the same PE class for getting the answer (odd or even).\n",
        "\n",
        "Because this PE class needs only 1 input and produces 0 or 1 output, we are going to create it by using a IterativePE type."
      ],
      "metadata": {
        "id": "t_AefmEtKK19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dispel4py.base import IterativePE\n",
        "\n",
        "class Divideby2(IterativePE):\n",
        "\n",
        "    def __init__(self, compare):\n",
        "        IterativePE.__init__(self)\n",
        "        self.compare = compare\n",
        "\n",
        "    def _process(self, data):\n",
        "        if data % 2 == self.compare:\n",
        "            return data"
      ],
      "metadata": {
        "id": "S-orGyjvKQm-"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Finally, the last PE in this workflow is going to receive two inputs streams. This PE will require two lists for grouping even and odd numbers. Therefore, GenericPE type is going to be the choice for creating this PE class. This type of PE requires to add the input (\"odd\" and \"even\") and output (\"output\") streams in the __init__ method. Because we need to store the data between different iterations, we create member variables in the __init__ method.\n",
        "\n",
        "During the _process method of this PE, the numbers received through its inputs will be appended to one list or another.\n",
        "\n",
        "As you can imagine, those lists can be imbalanced and one could have more elements than the other (because the producer PE has randomly generated more odd numbers than even, or the other way around). Therefore, in order to check if there are the numbers that have not been paired up (or \"left over\"), we can use the _postprocess method for printing out which data has not be paired before. The _postprocess method is launched only once per PE after all processing has completed.\n"
      ],
      "metadata": {
        "id": "ODsdviRKKPn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dispel4py.core import GenericPE\n",
        "\n",
        "class PairProducer(GenericPE):\n",
        "\n",
        "    def __init__(self):\n",
        "        GenericPE.__init__(self)\n",
        "        self._add_input(\"odd\")\n",
        "        self._add_input(\"even\")\n",
        "        self._add_output(\"output\")\n",
        "        self.list_odd=[]\n",
        "        self.list_even=[]\n",
        "\n",
        "    def _process(self, inputs):\n",
        "        if \"odd\" in inputs:\n",
        "            self.list_odd.append(inputs[\"odd\"])\n",
        "        if \"even\" in inputs:\n",
        "            self.list_even.append(inputs[\"even\"])\n",
        "\n",
        "        while self.list_odd and self.list_even:\n",
        "            self.write(\"output\", (self.list_odd.pop(0), self.list_even.pop(0)))\n",
        "\n",
        "    def _postprocess(self):\n",
        "        self.log('We are left behind: odd: %s, even: %s' % (self.list_odd, self.list_even))\n",
        "        self.list_odd = []\n",
        "        self.list_even = []"
      ],
      "metadata": {
        "id": "9vQX97suKXQv"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we only have to create the graph and connect the different PEs. Note that we create two PEs (filter_even and filter_odd) of the same type (Divideby2) to decide whether a number is odd or even. The output stream from the producer is connected to both filter PEs meaning that they both receive a copy of the same stream."
      ],
      "metadata": {
        "id": "7HFkEu33KcAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dispel4py.workflow_graph import WorkflowGraph\n",
        "\n",
        "producer = NumberProducer()\n",
        "filter_even = Divideby2(0)\n",
        "filter_odd = Divideby2(1)\n",
        "pair = PairProducer()\n",
        "\n",
        "graph = WorkflowGraph()\n",
        "graph.connect(producer, 'output', filter_even, 'input')\n",
        "graph.connect(producer, 'output', filter_odd, 'input')\n",
        "graph.connect(filter_even, 'output', pair, 'even')\n",
        "graph.connect(filter_odd, 'output', pair, 'odd')\n"
      ],
      "metadata": {
        "id": "OZzCOtq3Kasl"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's run this workflow with the sequential simple processor as we did before."
      ],
      "metadata": {
        "id": "nWL20xDtKjkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dispel4py.new.simple_process import process as simple_process\n",
        "simple_process(graph, {producer: 20})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaLm_SI_Km-u",
        "outputId": "6f25c0b7-56da-45d8-f6d2-e910d3292a1c"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs: {'NumberProducer19': 20}\n",
            "PairProducer22: We are left behind: odd: [], even: [144, 314, 510, 550, 412, 978, 742, 368]\n",
            "SimplePE: Processed 1 iteration.\n",
            "Outputs: {'PairProducer22': {'output': [(905, 422), (33, 26), (467, 852), (835, 62), (543, 754), (87, 714)]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Command line\n",
        "\n",
        "Once again we ned to copy the workflow and the PEs into a file. For doing this are going to use the `write_cell_above_to file` function.\n",
        "\n",
        "Remember, that each time we use this function is going to copy the cell above into the desired file (e.g. `evenodd.py`), and it needs a unique identifier each time (e.g. `id:example1b`).\n",
        "\n",
        "**Note**: You can also upload the `evenodd.py` workflow, downloading first to your local machine from [here](https://github.com/rosafilgueira/Workflows_Seminar/blob/main/d4py_tutorial_workflows/evenodd.py) and upload it to this Notebook later.\n"
      ],
      "metadata": {
        "id": "HFDB3l4xLAa2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "from dispel4py.base import ProducerPE, IterativePE\n",
        "from dispel4py.core import GenericPE\n",
        "from dispel4py.workflow_graph import WorkflowGraph\n",
        "from dispel4py.core import GenericPE\n",
        "import random\n",
        "\n",
        "class NumberProducer(ProducerPE):\n",
        "    def __init__(self):\n",
        "        ProducerPE.__init__(self)\n",
        "        \n",
        "    def _process(self, inputs):\n",
        "        result= random.randint(1, 1000)\n",
        "        return result\n",
        "        #OR: self.write('output', result)\n",
        "\n",
        "class Divideby2(IterativePE):\n",
        "    def __init__(self, compare):\n",
        "        IterativePE.__init__(self)\n",
        "        self.compare = compare\n",
        "    def _process(self, data):\n",
        "        if data % 2 == self.compare:\n",
        "            return data\n",
        "          \n",
        "class PairProducer(GenericPE):\n",
        "    def __init__(self):\n",
        "        GenericPE.__init__(self)\n",
        "        self._add_input(\"odd\")\n",
        "        self._add_input(\"even\")\n",
        "        self._add_output(\"output\")\n",
        "        self.list_odd=[]\n",
        "        self.list_even=[]\n",
        "      \n",
        "    def _process(self, inputs):\n",
        "        if \"odd\" in inputs:\n",
        "            self.list_odd.append(inputs[\"odd\"])\n",
        "        if \"even\" in inputs:\n",
        "            self.list_even.append(inputs[\"even\"])\n",
        "       \n",
        "        while self.list_odd and self.list_even:\n",
        "            self.write(\"output\", (self.list_odd.pop(0), self.list_even.pop(0)))\n",
        "    \n",
        "    def _postprocess(self):\n",
        "        self.log('We are left behind: odd: %s, even: %s' % (self.list_odd, self.list_even))\n",
        "        self.list_odd = []\n",
        "        self.list_even = []\n",
        "\n",
        "producer = NumberProducer()\n",
        "filter_even = Divideby2(0)\n",
        "filter_odd = Divideby2(1)\n",
        "pair = PairProducer()\n",
        "\n",
        "graph = WorkflowGraph()\n",
        "graph.connect(producer, 'output', filter_even, 'input')\n",
        "graph.connect(producer, 'output', filter_odd, 'input')\n",
        "graph.connect(filter_even, 'output', pair, 'even')\n",
        "graph.connect(filter_odd, 'output', pair, 'odd')\n",
        "```"
      ],
      "metadata": {
        "id": "fXIh-DaGLHnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <font size='4'>Run the cell above</font>\n",
        "search_term = 'id:example1b'\n",
        "write_cell_above_to_file(search_term, 'evenodd.py')"
      ],
      "metadata": {
        "id": "DKYCPv86LhF-"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!dispel4py simple evenodd.py -i 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3McZlnCFLpRa",
        "outputId": "0027ca47-e11f-4c7f-9285-1ec90eb5a638"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 20 iterations.\n",
            "RUN ARGS: \n",
            "Namespace(target='simple', module='evenodd.py', attr=None, file=None, data=None, iter=20, provenance=None)\n",
            "==========\n",
            "Inputs: {'NumberProducer0': 20}\n",
            "PairProducer3: We are left behind: odd: [], even: [62, 302]\n",
            "SimplePE: Processed 1 iteration.\n",
            "Outputs: {'PairProducer3': {'output': [(297, 148), (391, 14), (339, 800), (25, 66), (399, 530), (991, 570), (187, 786), (539, 410), (525, 484)]}}\n",
            "ELAPSED TIME: 0.0007524490356445312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dispel4py multi evenodd.py -i 100 -n 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWMRqSgGNPmG",
        "outputId": "adc6e4e0-e8da-406a-f32b-50e2e6bb4d9f"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 100 iterations.\n",
            "RUN ARGS: \n",
            "Namespace(target='multi', module='evenodd.py', attr=None, file=None, data=None, iter=100, provenance=None, simple=False, num=4)\n",
            "==========\n",
            "Processes: {'NumberProducer0': range(0, 1), 'Divideby21': range(1, 2), 'Divideby22': range(2, 3), 'PairProducer3': range(3, 4)}\n",
            "NumberProducer0 (rank 0): Processed 100 iterations.\n",
            "Divideby22 (rank 2): Processed 100 iterations.\n",
            "Divideby21 (rank 1): Processed 100 iterations.\n",
            "PairProducer3 (rank 3): We are left behind: odd: [], even: [244, 110, 668, 852, 696, 766]\n",
            "PairProducer3 (rank 3): Processed 100 iterations.\n",
            "ELAPSED TIME: 0.024795055389404297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The data streaming classic: WordCount!!\n",
        "\n",
        "We can not leave this tutorial without a streaming classic example. WordCount example reads a text and counts how often words occur.\n"
      ],
      "metadata": {
        "id": "eVFprITFOAWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dispel4py.core import GenericPE\n",
        "\n",
        "class SplitLines(GenericPE):\n",
        "\n",
        "    def __init__(self):\n",
        "        GenericPE.__init__(self)\n",
        "        self._add_input(\"input\")\n",
        "        self._add_output(\"output\")\n",
        "\n",
        "    def _process(self, inputs):\n",
        "        for line in inputs[\"input\"].splitlines():\n",
        "            self.write(\"output\", line)"
      ],
      "metadata": {
        "id": "8A9mu7xcOLzt"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dispel4py.base import IterativePE\n",
        "\n",
        "class SplitWords(IterativePE):\n",
        "\n",
        "    def __init__(self):\n",
        "        IterativePE.__init__(self)\n",
        "\n",
        "    def _process(self, data):\n",
        "        for word in data.split(\" \"):\n",
        "            self.write(\"output\", (word,1))"
      ],
      "metadata": {
        "id": "Oh8R-5Z8ONSO"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "class CountWords(GenericPE):\n",
        "    def __init__(self):\n",
        "        GenericPE.__init__(self)\n",
        "        self._add_input(\"input\", grouping=[0])\n",
        "        self._add_output(\"output\")\n",
        "        self.count=defaultdict(int)\n",
        "\n",
        "    def _process(self, inputs):\n",
        "        word, count = inputs['input']\n",
        "        self.count[word] += count\n",
        "\n",
        "    def _postprocess(self):\n",
        "        self.write('output', self.count)"
      ],
      "metadata": {
        "id": "FxTCjlR3ORM0"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dispel4py.workflow_graph import WorkflowGraph\n",
        "\n",
        "split = SplitLines()\n",
        "words = SplitWords()\n",
        "count = CountWords()\n",
        "\n",
        "graph = WorkflowGraph()\n",
        "graph.connect(split, 'output', words, 'input')\n",
        "graph.connect(words, 'output', count, 'input')"
      ],
      "metadata": {
        "id": "1Qq7TqnOOTsJ"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dispel4py.new.simple_process import process as simple_process\n",
        "simple_process(graph, {split: [ {'input' : \"Hello Hello something more World World World\"}] })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ_j-MluOV8a",
        "outputId": "5e3aa1b5-1d39-4e72-b952-081353ec2ba0"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs: {'SplitLines26': [{'input': 'Hello Hello something more World World World'}]}\n",
            "SimplePE: Processed 1 iteration.\n",
            "Outputs: {'CountWords28': {'output': [defaultdict(<class 'int'>, {'Hello': 2, 'something': 1, 'more': 1, 'World': 3})]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Command line\n",
        "\n",
        "\n",
        "Once again we ned to copy the workflow and the PEs into a file. For doing this are going to use the write_cell_above_to file function.\n",
        "\n",
        "Remember, that each time we use this function is going to copy the cell above into the desired file (e.g. wordcount.py), and it needs a unique identifier each time (e.g. id:example1c).\n",
        "\n",
        "**Note**: You can also upload the `wordcount.py` workflow, downloading first to your local machine from [here](https://github.com/rosafilgueira/Workflows_Seminar/blob/main/d4py_tutorial_workflows/wordcount.py) and upload it to this Notebook later."
      ],
      "metadata": {
        "id": "JJr2W93BOh0D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "from dispel4py.core import GenericPE\n",
        "from dispel4py.base import IterativePE\n",
        "from dispel4py.workflow_graph import WorkflowGraph\n",
        "import os\n",
        "\n",
        "class SplitLines(GenericPE):\n",
        "    def __init__(self):\n",
        "        GenericPE.__init__(self)\n",
        "        self._add_input(\"input\")\n",
        "        self._add_output(\"output\")\n",
        "        \n",
        "    def _process(self, inputs):\n",
        "        for line in inputs[\"input\"].splitlines():\n",
        "            self.write(\"output\", line)\n",
        "\n",
        "class SplitWords(IterativePE):\n",
        "\n",
        "    def __init__(self):\n",
        "        IterativePE.__init__(self)\n",
        "        \n",
        "    def _process(self, data):\n",
        "        for word in data.split(\" \"):\n",
        "            self.write(\"output\", (word,1))\n",
        "\n",
        "\n",
        "class CountWords(GenericPE):\n",
        "    def __init__(self):\n",
        "        \n",
        "        from collections import defaultdict\n",
        "        GenericPE.__init__(self)\n",
        "        self._add_input(\"input\", grouping=[0])\n",
        "        self._add_output(\"output\")\n",
        "        self.count=defaultdict(int)\n",
        "        \n",
        "    def _process(self, inputs):\n",
        "        word, count = inputs['input']\n",
        "        self.count[word] += count\n",
        "    \n",
        "    def _postprocess(self):\n",
        "        self.write('output', self.count)\n",
        "\n",
        "split = SplitLines()\n",
        "split.name ='split'\n",
        "words = SplitWords()\n",
        "count = CountWords()\n",
        "\n",
        "\n",
        "graph = WorkflowGraph()\n",
        "graph.connect(split, 'output', words, 'input')\n",
        "graph.connect(words, 'output', count, 'input')\n",
        "```"
      ],
      "metadata": {
        "id": "WpdJ1eXbOp0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <font size='4'>Run the cell above</font>\n",
        "search_term = 'id:example1c'\n",
        "write_cell_above_to_file(search_term, 'wordcount.py')"
      ],
      "metadata": {
        "id": "jSGilxAyO_T7"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Atention how we give the iput data to the workflow.\n",
        "\n",
        "In this case is **very important** that we give a name to the first PE:\n",
        "\n",
        "``` split.name= 'split'```\n",
        "\n",
        "Because we are going to use it later to specify the PE (`split`) for which the input dictionary is for :\n",
        "```\n",
        "\n",
        "-d '{\"split\" : [{\"input\" : \"Hello Hello something more World World World\"}]}'\n",
        "\n",
        "```\n",
        "\n",
        "* -d: This flag stands for 'data', and it allows you to input JSON-formatted data directly into the workflow from the command line.\n",
        "\n",
        "* '{\"split\" : [{\"input\" : \"Hello Hello something more World World World\"}]}': This is the JSON data being passed to the workflow. The JSON object contains one key, split, which is likely the name of a processing element or input stream in the workflow. The value is a list of dictionaries, each containing an input key with a string of text as its value."
      ],
      "metadata": {
        "id": "dzkTcV-sQ2Jd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!dispel4py simple wordcount.py -d '{\"split\" : [{\"input\" : \"Hello Hello something more World World World\"}]}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyBRpLE_PEE-",
        "outputId": "2f749b89-0664-4c3f-9a57-38c10591795f"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RUN ARGS: \n",
            "Namespace(target='simple', module='wordcount.py', attr=None, file=None, data='{\"split\" : [{\"input\" : \"Hello Hello something more World World World\"}]}', iter=1, provenance=None)\n",
            "==========\n",
            "Inputs: {'split0': [{'input': 'Hello Hello something more World World World'}]}\n",
            "SimplePE: Processed 1 iteration.\n",
            "Outputs: {'CountWords2': {'output': [defaultdict(<class 'int'>, {'Hello': 2, 'something': 1, 'more': 1, 'World': 3})]}}\n",
            "ELAPSED TIME: 0.0005199909210205078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Useful dispel4py Flags\n",
        "\n",
        "-h, --help: Show the help message and exit.\n",
        "\n",
        "-l, --loglevel: Set the logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL).\n",
        "\n",
        "-v, --verbose: Enable verbose logging.\n",
        "\n",
        "-n, --num: number of processes or threads)\n",
        "\n",
        "-a ATTR, --attr ATTR: Set an attribute for the graph.\n",
        "\n",
        "-d DATA, --data DATA: Input data as a JSON string. This is how you provide the initial data for the workflow.\n",
        "\n",
        "-f FILE, --file FILE: Input data as a JSON file. This is an alternative to -d where you can specify a file containing the JSON data.\n",
        "\n",
        "-i ITERATIONS, --iterations ITERATIONS: The number of iterations to run.\n",
        "\n",
        "-t, --trace: Trace the execution of the workflow.\n",
        "\n",
        "-s, --stream: Stream data between iterations instead of between PEs.\n",
        "\n"
      ],
      "metadata": {
        "id": "OKMP1-EZSNjb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary of dispel4py Mappings\n",
        "\n",
        "\n",
        "### Sequential\n",
        "\n",
        "* simple: Executes dataflow graphs sequentially within a single process. This is suitable for smaller, less complex data processing tasks.\n",
        "\n",
        "### Parallel\n",
        "\n",
        "Fixed workload distribution (supports both stateful and stateless PEs)\n",
        "\n",
        "* mpi: Utilizes the Message Passing Interface (MPI) to distribute computations across multiple nodes, allowing for parallel processing in a distributed memory environment.\n",
        "* multi: Runs multiple instances of a dataflow graph in parallel on a single machine using the multiprocessing library in Python.\n",
        "* zmq_multi: Similar to multi, but uses the ZeroMQ library for managing parallel execution within a single machine.\n",
        "\n",
        "* redis: Executes multiple instances of a dataflow graph in parallel using Redis as a messaging system.\n",
        "\n",
        "\n",
        "### Dynamic workload distribution (supports only stateless PEs)\n",
        "\n",
        "* dyn_multi: Runs multiple instances with dynamic workload assignment (without autoscaling) using Python’s multiprocessing library.\n",
        "* dyn_auto_multi: Similar to dyn_multi, but includes autoscaling capabilities and can adjust the number of threads dynamically.\n",
        "* dyn_redis: Runs multiple instances with dynamic workload assignment (without autoscaling) using Redis.\n",
        "* dyn_auto_redis: Similar to dyn_redis, but allows for autoscaling and dynamic thread adjustments.\n",
        "\n",
        "### Hybrid workload distribution (supports both stateful and stateless PEs)\n",
        "\n",
        "* hybrid_redis: A hybrid approach that runs multiple instances of a dataflow graph using Redis. Stateless PEs have dynamically assigned workloads, while Stateful PEs have fixed assignments."
      ],
      "metadata": {
        "id": "e5lsehmrS6zy"
      }
    }
  ]
}